"""
Title Generator for Instagram-style captions

Uses Qwen2-1.5B-Instruct LLM to generate creative, artistic Vietnamese titles
for images based on:
- AI-generated caption (Vietnamese)
- Image classification (Heritage/Culture/Nature/People)
- Place detection (ÄÃ  Náºµng/Há»™i An landmarks)

Performance: ~500ms-1.5s on GPU (RTX 3050)
VRAM usage: ~1.5-2GB
"""

from typing import List, Optional, Dict
import re
import sys
import os
from pathlib import Path

# Lazy load LLM to save memory
_LLM_MODEL = None
_LLM_ENABLED = False

# ÄÃ  Náºµng / Há»™i An place detection dictionary
DA_NANG_PLACES = {
    # ÄÃ  Náºµng landmarks
    "Ä‘Ã  náºµng": "ÄÃ  Náºµng",
    "da nang": "ÄÃ  Náºµng",
    "sÃ´ng hÃ n": "SÃ´ng HÃ n",
    "song han": "SÃ´ng HÃ n",
    "cáº§u rá»“ng": "Cáº§u Rá»“ng",
    "cau rong": "Cáº§u Rá»“ng",
    "dragon bridge": "Cáº§u Rá»“ng",
    "sÆ¡n trÃ ": "BÃ¡n Ä‘áº£o SÆ¡n TrÃ ",
    "son tra": "BÃ¡n Ä‘áº£o SÆ¡n TrÃ ",
    "linh á»©ng": "ChÃ¹a Linh á»¨ng",
    "linh ung": "ChÃ¹a Linh á»¨ng",
    "lady buddha": "ChÃ¹a Linh á»¨ng",
    "ngÅ© hÃ nh sÆ¡n": "NgÅ© HÃ nh SÆ¡n",
    "ngu hanh son": "NgÅ© HÃ nh SÆ¡n",
    "marble mountains": "NgÅ© HÃ nh SÆ¡n",
    "má»¹ khÃª": "Biá»ƒn Má»¹ KhÃª",
    "my khe": "Biá»ƒn Má»¹ KhÃª",
    "non nÆ°á»›c": "BÃ£i biá»ƒn Non NÆ°á»›c",
    "non nuoc": "BÃ£i biá»ƒn Non NÆ°á»›c",
    "bÃ£i ráº¡ng": "BÃ£i biá»ƒn BÃ£i Ráº¡ng",
    "bai rang": "BÃ£i biá»ƒn BÃ£i Ráº¡ng",
    
    # Há»™i An landmarks
    "há»™i an": "Há»™i An",
    "hoi an": "Há»™i An",
    "phá»‘ cá»•": "Phá»‘ cá»• Há»™i An",
    "pho co": "Phá»‘ cá»• Há»™i An",
    "old town": "Phá»‘ cá»• Há»™i An",
    "chÃ¹a cáº§u": "ChÃ¹a Cáº§u",
    "chua cau": "ChÃ¹a Cáº§u",
    "japanese bridge": "ChÃ¹a Cáº§u",
    "cáº§u nháº­t báº£n": "ChÃ¹a Cáº§u",
    "rá»«ng dá»«a": "Rá»«ng dá»«a Báº£y Máº«u",
    "rung dua": "Rá»«ng dá»«a Báº£y Máº«u",
    "coconut forest": "Rá»«ng dá»«a Báº£y Máº«u",
    "báº£y máº«u": "Rá»«ng dá»«a Báº£y Máº«u",
    "bay mau": "Rá»«ng dá»«a Báº£y Máº«u",
    "Ä‘Ã¨n lá»“ng": "Há»™i An (Ä‘Ã¨n lá»“ng)",
    "den long": "Há»™i An (Ä‘Ã¨n lá»“ng)",
    "lantern": "Há»™i An (Ä‘Ã¨n lá»“ng)",
    "phá»‘ há»™i": "Phá»‘ Há»™i",
    "pho hoi": "Phá»‘ Há»™i",
    "sÃ´ng thu bá»“n": "SÃ´ng Thu Bá»“n",
    "song thu bon": "SÃ´ng Thu Bá»“n",
    "thu bon river": "SÃ´ng Thu Bá»“n"
}

# Category to Vietnamese mapping
CATEGORY_VI = {
    "Heritage & Architecture": "Di sáº£n & Kiáº¿n trÃºc",
    "Culture & Art": "VÄƒn hoÃ¡ & Nghá»‡ thuáº­t", 
    "Nature & Landscape": "ThiÃªn nhiÃªn & Cáº£nh quan",
    "People & Events": "Con ngÆ°á»i & Sá»± kiá»‡n"
}

# Vibe/mood suggestions based on category
CATEGORY_VIBE = {
    "Heritage & Architecture": "hoÃ i cá»•, trang nghiÃªm, lá»‹ch sá»­",
    "Culture & Art": "sÃ´i Ä‘á»™ng, Ä‘áº­m cháº¥t nghá»‡ thuáº­t, Ä‘áº·c sáº¯c",
    "Nature & Landscape": "thÆ¡ má»™ng, yÃªn bÃ¬nh, hÃ¹ng vÄ©",
    "People & Events": "áº¥m Ã¡p, gáº§n gÅ©i, Ä‘áº§y cáº£m xÃºc"
}

# Place-specific vibes (override category vibe if place detected)
PLACE_VIBE = {
    "ÄÃ  Náºµng": "hiá»‡n Ä‘áº¡i, nÄƒng Ä‘á»™ng, biá»ƒn xanh",
    "SÃ´ng HÃ n": "lÃ£ng máº¡n, chiá»u má»m, Ã¡nh Ä‘Ã¨n lung linh",
    "Cáº§u Rá»“ng": "huyá»n thoáº¡i, rá»±c rá»¡, biá»ƒu tÆ°á»£ng thÃ nh phá»‘",
    "BÃ¡n Ä‘áº£o SÆ¡n TrÃ ": "hoang sÆ¡, hÃ¹ng vÄ©, thiÃªn nhiÃªn báº¡t ngÃ n",
    "ChÃ¹a Linh á»¨ng": "linh thiÃªng, tÄ©nh láº·ng, bÃ¬nh yÃªn",
    "NgÅ© HÃ nh SÆ¡n": "huyá»n bÃ­, linh thiÃªng, nÃºi Ä‘Ã¡ cá»• kÃ­nh",
    "Biá»ƒn Má»¹ KhÃª": "sÃ³ng vá»—, cÃ¡t tráº¯ng, náº¯ng vÃ ng",
    "Há»™i An": "hoÃ i niá»‡m, Ä‘Ã¨n vÃ ng, phá»‘ xÆ°a",
    "Phá»‘ cá»• Há»™i An": "cá»• kÃ­nh, hoÃ i niá»‡m, Ä‘Ã¨n lá»“ng rá»±c rá»¡",
    "ChÃ¹a Cáº§u": "cá»• kÃ­nh, biá»ƒu tÆ°á»£ng vÄƒn hoÃ¡, nÃ©t xÆ°a",
    "Rá»«ng dá»«a Báº£y Máº«u": "xanh mÃ¡t, thanh bÃ¬nh, dá»«a nghiÃªng"
}


def detect_place(caption_vi: str) -> Optional[str]:
    """
    Detect ÄÃ  Náºµng/Há»™i An places from Vietnamese caption
    
    Args:
        caption_vi: Vietnamese caption text
        
    Returns:
        Place name if detected, None otherwise
    """
    if not caption_vi:
        return None
    
    text_lower = caption_vi.lower()
    
    # Check for place keywords
    for keyword, place_name in DA_NANG_PLACES.items():
        if keyword in text_lower:
            return place_name
    
    return None


def get_vibe(category: Optional[str] = None, place: Optional[str] = None) -> str:
    """
    Get mood/vibe description for title generation
    
    Priority: place-specific vibe > category vibe > default
    
    Args:
        category: Image category (Heritage/Culture/Nature/People)
        place: Detected place name
        
    Returns:
        Vibe description string
    """
    # Priority 1: Place-specific vibe
    if place:
        for place_key, vibe in PLACE_VIBE.items():
            if place_key in place:
                return vibe
    
    # Priority 2: Category vibe
    if category and category in CATEGORY_VIBE:
        return CATEGORY_VIBE[category]
    
    # Default
    return "Ä‘áº¹p, áº¥n tÆ°á»£ng, Ä‘Ã¡ng nhá»›"


def get_llm():
    """
    Lazy load LLM model to save memory
    
    Returns:
        Llama model instance or None if loading fails
    """
    global _LLM_MODEL, _LLM_ENABLED
    
    if _LLM_MODEL is not None:
        return _LLM_MODEL
    
    if _LLM_ENABLED:  # Already tried and succeeded
        return _LLM_MODEL
    
    try:
        from llama_cpp import Llama
        import os
        
        # Try multiple possible paths (depends on where script is run from)
        possible_paths = [
            Path("models/llm/qwen2-1_5b-instruct-q4_k_m.gguf"),  # From root
            Path("../models/llm/qwen2-1_5b-instruct-q4_k_m.gguf"),  # From ai/
        ]
        
        model_path = None
        for p in possible_paths:
            if p.exists():
                model_path = p
                break
        
        if model_path is None:
            print(f"âš ï¸  LLM model not found in any of these locations:")
            for p in possible_paths:
                print(f"     - {p.absolute()}")
            print("   Run 'python download_llm.py' to download the model")
            return None
        
        # print(f"ğŸ”„ Loading LLM from: {model_path}...")  # Bá» log chi tiáº¿t
        
        # Suppress llama.cpp stderr warnings
        stderr_backup = sys.stderr
        sys.stderr = open(os.devnull, 'w')
        
        try:
            _LLM_MODEL = Llama(
                model_path=str(model_path),
                n_gpu_layers=-1,  # Full GPU offload (RTX 3050)
                n_ctx=2048,       # Context window
                n_batch=512,      # Batch size for prompt processing
                n_threads=4,      # CPU threads for non-GPU ops
                verbose=False,
                seed=42           # Reproducible results
            )
        finally:
            # Restore stderr
            sys.stderr.close()
            sys.stderr = stderr_backup
        
        _LLM_ENABLED = True
        print("âœ… LLM Ä‘Ã£ táº£i xong (chá»‰ láº§n Ä‘áº§u)")
        return _LLM_MODEL
        
    except ImportError as e:
        print(f"âš ï¸  llama-cpp-python not installed: {e}")
        print("   Install with: pip install llama-cpp-python")
        print("   Or with CUDA: pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121")
        return None
        
    except Exception as e:
        print(f"âš ï¸  Error loading LLM: {e}")
        return None


def build_prompt(
    caption_vi: str,
    category: Optional[str] = None,
    place: Optional[str] = None
) -> str:
    """
    Build LLM prompt for title generation
    
    Args:
        caption_vi: Vietnamese caption/description
        category: Image category (Heritage/Culture/Nature/People)
        place: Detected place name
        
    Returns:
        Formatted prompt string
    """
    # Get category in Vietnamese
    category_vi = CATEGORY_VI.get(category, category) if category else "KhÃ´ng xÃ¡c Ä‘á»‹nh"
    
    # Get vibe/mood
    vibe = get_vibe(category, place)
    
    # Place info
    place_info = f"Äá»‹a Ä‘iá»ƒm: {place}" if place else "Äá»‹a Ä‘iá»ƒm: KhÃ´ng xÃ¡c Ä‘á»‹nh"
    
    # System prompt
    system = (
        "Báº¡n lÃ  ngÆ°á»i viáº¿t caption Instagram cho du lá»‹ch Viá»‡t Nam. "
        "Táº¡o caption Ä‘Æ¡n giáº£n, dá»… hiá»ƒu, gáº§n gÅ©i nhÆ° ngÆ°á»i bÃ¬nh thÆ°á»ng chia sáº». "
        "DÃ¹ng tiáº¿ng Viá»‡t Ä‘á»i thÆ°á»ng, tá»± nhiÃªn, KHÃ”NG dÃ¹ng tá»« cá»•, tá»« vÄƒn chÆ°Æ¡ng phá»©c táº¡p. "
        "Äá»™ dÃ i 8-15 tá»«, KHÃ”NG dÃ¹ng emoji, KHÃ”NG giÃ¡o huáº¥n."
    )
    
    # User prompt
    user = f"""ThÃ´ng tin áº£nh:
- MÃ´ táº£: {caption_vi}
- Danh má»¥c: {category_vi}
- {place_info}
- Cáº£m xÃºc: {vibe}

YÃªu cáº§u:
1. Táº¡o ÄÃšNG 3 tiÃªu Ä‘á» khÃ¡c nhau
2. Má»—i tiÃªu Ä‘á» trÃªn 1 dÃ²ng
3. Äá»™ dÃ i: 8-15 tá»«
4. Tá»« ngá»¯: ÄÆ¡n giáº£n, dá»… hiá»ƒu, Ä‘á»i thÆ°á»ng (KHÃ”NG dÃ¹ng tá»« cá»•, tá»« vÄƒn chÆ°Æ¡ng)
5. Phong cÃ¡ch: Tá»± nhiÃªn, gáº§n gÅ©i nhÆ° ngÆ°á»i bÃ¬nh thÆ°á»ng viáº¿t Instagram
6. KHÃ”NG dÃ¹ng emoji
7. KHÃ”NG Ä‘Ã¡nh sá»‘ thá»© tá»±
8. CÃ¢u vÄƒn sÃºc tÃ­ch, rÃµ nghÄ©a

VÃ­ dá»¥ Tá»T:
- "SÃ¡ng sá»›m á»Ÿ phá»‘ cá»• Há»™i An Ä‘áº¹p quÃ¡"
- "Cáº§u Rá»“ng lung linh Ã¡nh Ä‘Ã¨n khi vá» Ä‘Ãªm"
- "ThiÃªn nhiÃªn SÆ¡n TrÃ  xanh mÆ°á»›t báº¥t ngá»"

VÃ­ dá»¥ Xáº¤U (quÃ¡ vÄƒn chÆ°Æ¡ng, trÃ¡nh):
- "Há»“ng HoÃ ng Má»™ng Vá»ng: Má»™t Trang Sá»­ HoÃ i Há»£i"
- "Kinh ÄÃ´ Ãnh VÃ ng Trong MÆ¡ Má»™ng"
- "ThiÃªn ÄÆ°á»ng Xanh NgÃ¡t Tuyá»‡t Vá»i"

Xuáº¥t 3 tiÃªu Ä‘á»:"""
    
    # Qwen2 chat format
    prompt = f"<|im_start|>system\n{system}<|im_end|>\n<|im_start|>user\n{user}<|im_end|>\n<|im_start|>assistant\n"
    
    return prompt


def parse_titles(llm_output: str) -> List[str]:
    """
    Parse LLM output to extract 3 titles
    
    Args:
        llm_output: Raw LLM output text
        
    Returns:
        List of 3 titles (or fewer if parsing fails)
    """
    # Split by newlines
    lines = llm_output.strip().split('\n')
    
    titles = []
    for line in lines:
        # Clean up
        line = line.strip()
        
        # Remove common prefixes
        line = re.sub(r'^[-*â€¢]\s*', '', line)  # Remove bullet points
        line = re.sub(r'^\d+[.)]\s*', '', line)  # Remove numbering
        line = re.sub(r'^Title\s*\d*:\s*', '', line, flags=re.IGNORECASE)  # Remove "Title:"
        
        # Skip empty or too short
        if not line or len(line.split()) < 3:
            continue
        
        # Skip lines with emojis (shouldn't happen but just in case)
        if any(ord(c) > 127 and ord(c) in range(0x1F300, 0x1F9FF) for c in line):
            continue
        
        # Add to titles
        titles.append(line)
        
        # Stop at 3
        if len(titles) >= 3:
            break
    
    # Fallback if parsing failed
    if not titles:
        titles = [llm_output.strip()]
    
    return titles[:3]


def generate_titles(
    caption_vi: str,
    category: Optional[str] = None,
    place: Optional[str] = None,
    max_tokens: int = 180,
    temperature: float = 0.85,
    top_p: float = 0.9,
    num_titles: int = 3
) -> Dict[str, any]:
    """
    Generate Instagram-style titles for an image
    
    Args:
        caption_vi: Vietnamese caption/description
        category: Image category (Heritage/Culture/Nature/People)
        place: Detected place name (optional, will auto-detect from caption)
        max_tokens: Max tokens for LLM generation (increased for longer titles)
        temperature: Sampling temperature (higher = more creative)
        top_p: Nucleus sampling parameter
        num_titles: Number of titles to generate (default 3, can be 1 for API)
        
    Returns:
        Dict with:
            - titles: List[str] - Generated titles (length = num_titles)
            - place: str - Detected place
            - category: str - Category used
            - success: bool - Whether generation succeeded
            - error: Optional[str] - Error message if failed
    """
    # Auto-detect place if not provided
    if place is None:
        place = detect_place(caption_vi)
    
    # Try to load LLM
    llm = get_llm()
    
    if llm is None:
        # Fallback: generate simple titles without LLM
        print("âš ï¸  LLM not available, using fallback titles")
        category_vi = CATEGORY_VI.get(category, "Khoáº£nh kháº¯c")
        fallback_titles = [
            f"{category_vi} Ä‘Ã¡ng nhá»›",
            caption_vi[:50] if len(caption_vi) <= 50 else caption_vi[:47] + "...",
            f"{place}" if place else "Khung cáº£nh tuyá»‡t vá»i"
        ]
        return {
            "titles": fallback_titles,
            "place": place,
            "category": category,
            "success": False,
            "error": "LLM not available"
        }
    
    try:
        # Build prompt
        prompt = build_prompt(caption_vi, category, place)
        
        # Generate
        output = llm(
            prompt,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            stop=["<|im_end|>", "\n\n\n"],  # Stop tokens
            echo=False
        )
        
        # Extract text
        generated_text = output["choices"][0]["text"]
        
        # Parse titles
        titles = parse_titles(generated_text)
        
        # Láº¥y Ä‘Ãºng sá»‘ lÆ°á»£ng titles cáº§n thiáº¿t
        titles = titles[:num_titles] if titles else []
        
        return {
            "titles": titles,
            "place": place,
            "category": category,
            "success": True,
            "error": None
        }
        
    except Exception as e:
        print(f"âš ï¸  Error generating titles: {e}")
        
        # Fallback
        category_vi = CATEGORY_VI.get(category, "Khoáº£nh kháº¯c")
        fallback_titles = [
            f"{category_vi} Ä‘áº¹p",
            caption_vi[:50] if len(caption_vi) <= 50 else caption_vi[:47] + "...",
            f"{place}" if place else "áº¢nh tuyá»‡t vá»i"
        ]
        
        return {
            "titles": fallback_titles,
            "place": place,
            "category": category,
            "success": False,
            "error": str(e)
        }


# Test function
if __name__ == "__main__":
    print("Testing Title Generator...")
    print()
    
    # Test 1: Heritage
    print("Test 1: Heritage & Architecture")
    result = generate_titles(
        caption_vi="Má»™t ngÃ´i Ä‘á»n cá»• kÃ­nh vá»›i kiáº¿n trÃºc truyá»n thá»‘ng",
        category="Heritage & Architecture"
    )
    print(f"  Place: {result['place']}")
    print(f"  Titles:")
    for i, title in enumerate(result['titles'], 1):
        print(f"    {i}. {title}")
    print()
    
    # Test 2: ÄÃ  Náºµng
    print("Test 2: ÄÃ  Náºµng landmark")
    result = generate_titles(
        caption_vi="Cáº§u Rá»“ng lung linh Ã¡nh Ä‘Ã¨n vá» Ä‘Ãªm",
        category="Heritage & Architecture"
    )
    print(f"  Place: {result['place']}")
    print(f"  Titles:")
    for i, title in enumerate(result['titles'], 1):
        print(f"    {i}. {title}")
    print()
    
    # Test 3: Há»™i An
    print("Test 3: Há»™i An")
    result = generate_titles(
        caption_vi="Phá»‘ cá»• Há»™i An vá»›i nhá»¯ng chiáº¿c Ä‘Ã¨n lá»“ng Ä‘áº§y mÃ u sáº¯c",
        category="Culture & Art"
    )
    print(f"  Place: {result['place']}")
    print(f"  Titles:")
    for i, title in enumerate(result['titles'], 1):
        print(f"    {i}. {title}")
    print()

